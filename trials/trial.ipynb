{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import instructor\n",
    "\n",
    "from openai import OpenAI\n",
    "from typing import List\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "client = instructor.patch(OpenAI())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "\n",
    "\n",
    "class DateRange(BaseModel):\n",
    "    start: date\n",
    "    end: date\n",
    "\n",
    "\n",
    "class Query(BaseModel):\n",
    "    rewritten_query: str\n",
    "    published_daterange: DateRange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Query(rewritten_query='Recent developments in artificial intelligence', published_daterange=DateRange(start=datetime.date(2022, 1, 1), end=datetime.date(2022, 4, 30)))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def expand_query(q) -> Query:\n",
    "    return client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        response_model=Query,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": f\"You are a \",\n",
    "            },\n",
    "            {\"role\": \"user\", \"content\": f\"query: {q}\"},\n",
    "        ],\n",
    "    )\n",
    "\n",
    "\n",
    "query = expand_query(\"What are some recent developments in AI?\")\n",
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Query(rewritten_query='latest advancements in artificial intelligence 2023', published_daterange=DateRange(chain_of_thought=\"Since it's 2023 and the user is asking about recent developments, focusing on AI advancements from the beginning of this year to the present would be ideal to ensure the information is up-to-date.\", start=datetime.date(2023, 1, 1), end=datetime.date(2023, 4, 30)))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class DateRange(BaseModel):\n",
    "    chain_of_thought: str = Field(\n",
    "        description=\"Think step by step to plan what is the best time range to search in\"\n",
    "    )\n",
    "    start: date\n",
    "    end: date\n",
    "\n",
    "class Tools(BaseModel):\n",
    "    tool: str = Field(description=\"Tool to use for the search\")\n",
    "    description: str = Field(description=\"Description of the tool\")\n",
    "    link: str = Field(description=\"Link to the tool\")\n",
    "\n",
    "class Query(BaseModel):\n",
    "    rewritten_query: str = Field(\n",
    "        description=\"Rewrite the query to make it more specific\"\n",
    "    )\n",
    "    published_daterange: DateRange = Field(\n",
    "        description=\"Effective date range to search in\"\n",
    "    )\n",
    "\n",
    "\n",
    "def expand_query(q) -> Query:\n",
    "    return client.chat.completions.create(\n",
    "        model=\"gpt-4-1106-preview\",\n",
    "        response_model=Query,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": f\"You're a query understanding system for the Metafor Systems search engine. Here are some tips: ...\",\n",
    "            },\n",
    "            {\"role\": \"user\", \"content\": f\"query: {q}\"},\n",
    "        ],\n",
    "    )\n",
    "\n",
    "\n",
    "expand_query(\"What are some recent developments in AI?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"rewritten_query\": \"latest advancements in artificial intelligence\",\n",
      "    \"published_daterange\": {\n",
      "        \"chain_of_thought\": \"Since it's currently 2024 and 'recent' typically refers to developments that have occurred over the past year or so, the date range for the search could start from early 2023 to the present date in 2024.\",\n",
      "        \"start\": \"2023-01-01\",\n",
      "        \"end\": \"2024-05-12\"\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "querystring=\"What are some recent developments in AI?\"\n",
    "\n",
    "retrival=client.chat.completions.create(\n",
    "        model=\"gpt-4-1106-preview\",\n",
    "        response_model=Query,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": f\"You're a query understanding system for the Metafor Systems search engine. Today is {date.today()}. Here are some tips: ...\",\n",
    "            },\n",
    "            {\"role\": \"user\", \"content\": f\"query: {querystring}\"},\n",
    "        ],\n",
    "    )\n",
    "print(retrival.model_dump_json(indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"root_question\": \"What are the ships surrounding India and which of them has IMO=9987654?\",\n",
      "    \"plan\": [\n",
      "        {\n",
      "            \"id\": 1,\n",
      "            \"query\": \"Get details of ships surrounding India\",\n",
      "            \"endpoints\": [\n",
      "                \"vesselsInArea\"\n",
      "            ],\n",
      "            \"arguments\": [\n",
      "                \"input\"\n",
      "            ],\n",
      "            \"subquestions\": [\n",
      "                3\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"id\": 2,\n",
      "            \"query\": \"Fetch details of a specific vessel by IMO number 9987654\",\n",
      "            \"endpoints\": [\n",
      "                \"vesselByIMO\"\n",
      "            ],\n",
      "            \"arguments\": [\n",
      "                \"imo\"\n",
      "            ],\n",
      "            \"subquestions\": []\n",
      "        },\n",
      "        {\n",
      "            \"id\": 3,\n",
      "            \"query\": \"Define area polygon surrounding India\",\n",
      "            \"endpoints\": [\n",
      "                \"areas\"\n",
      "            ],\n",
      "            \"arguments\": [\n",
      "                \"filter\"\n",
      "            ],\n",
      "            \"subquestions\": []\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "class Endpoints(BaseModel):\n",
    "    id: int = Field(..., description=\"A unique identifier for the question\")\n",
    "    query: str = Field(..., description=\"The question decomposited as much as possible\")\n",
    "    endpoints: List[str] = Field(..., description=\"The graphql endpoint that is required to fetch data from the ai to answer this specific question\")\n",
    "    arguments: List[str] = Field(..., description=\"The parameters that are required to send in the query request to the endpoint\")\n",
    "    subquestions: List[int] = Field(\n",
    "        default_factory=list,\n",
    "        description=\"The other endpoints it relies on to get the data from to answer the question. Check each of the arguments of the endpoint to check if it is available if not add a subquestion to get the data from the other point that it can be retrived from\",\n",
    "    )\n",
    "\n",
    "\n",
    "class QueryPlan(BaseModel):\n",
    "    root_question: str = Field(..., description=\"The root question that the user asked\")\n",
    "    plan: List[Endpoints] = Field(\n",
    "        ..., description=\"\"\"The plan to answer the root question by querying different endpoints available in the graphql api\n",
    "        Make sure every information is present and to answer the question and decompose the question properly into each of it's respective endpoints\"\"\"\n",
    "    )\n",
    "\n",
    "\n",
    "retrival = client.chat.completions.create(\n",
    "    model=\"gpt-4-turbo\",\n",
    "    response_model=QueryPlan,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": '''You are a query understanding system capable of decomposing a question into subparamaters required to answer the question.\n",
    "            \n",
    "            The arguments which are present in different parts of the graphql endpoint i am about to use are as follows: \n",
    "           These are the endpoints that are available in graphql\n",
    "           type Query {\n",
    "  searchVesselsByIdentifier(identifier: String!, limit: PositiveInt = 20): [SimplifiedVessel]\n",
    "\n",
    "  \"\"\"Query - returns information on a single vessel behaviour\"\"\"\n",
    "  vessel(id: ObjectId!): VesselIntelligence\n",
    "\n",
    "  \"\"\"Query - returns information on a single vessel by its IMO\"\"\"\n",
    "  vesselByIMO(imo: String!): VesselIntelligence\n",
    "\n",
    "  \"\"\"Query - returns information on a multiple vessels by their IMO\"\"\"\n",
    "  vesselsByIMOs(imos: [String!]!): [VesselIntelligence]\n",
    "  vesselsByMMSI(mmsi: String!): [VesselIntelligence!]!\n",
    "  portExpectedArrivals(input: PortExpectedArrivalsInput!): PortExpectedArrivalsConnection!\n",
    "  vesselsInPort(input: VesselsInPortInput!): VesselsInPortConnection!\n",
    "  departedFromPortVessels(input: DepartedFromPortVesselsInput!): DepartedFromPortVesselsConnection!\n",
    "  vesselPropertyChanges(input: VesselPropertyChangesInput!): VesselPropertyChangesConnection!\n",
    "\n",
    "  \"\"\"\n",
    "  The API requires selection of a user defined area and selected time range \n",
    "  and returns a list of vessels that transmitted in that selected location and selected time\n",
    "  \"\"\"\n",
    "  vesselsInArea(input: VesselsInAreaInput!): VesselsInAreaConnection!\n",
    "  vesselsCurrentlyInArea(input: VesselsCurrentlyInAreaInput!): VesselsCurrentlyInAreaConnection!\n",
    "  riskyVesselsInArea(input: RiskyVesselsInAreaInput!): RiskyVesselsInAreaConnection!\n",
    "  getActivitiesByDatesAndPolygon(type: ActivityTypes!, timeRange: DateTimeRange!, polygonId: ObjectId!): [Activity]\n",
    "  activitiesInPolygon(input: ActivitiesInPolygonInput!): ActivitiesInPolygonConnection!\n",
    "  vesselTimeline(input: VesselTimelineInput!): VesselTimelineConnection!\n",
    "  advancedVesselsSearch(input: AdvancedVesselSearchInput!): SearchResultsOutput\n",
    "  areas(filter: AreaFilterInput!): [FeatureObject]\n",
    "  searchCompaniesByTerm(searchTerm: String!): [Company!]!\n",
    "  projectVOIs: [VOI]\n",
    "  voiAuditLogs(input: VOIAuditLogsInput!): VOIAuditLogsConnection!\n",
    "  complianceServiceReport(imos: [String], timeRange: DateTimeRange, programs: [ComplianceProgram], risks: [Int]): ComplianceServiceReport\n",
    "  complianceRiskBy(input: ComplianceRiskByInput!): ComplianceRiskByConnection!\n",
    "  complianceVesselBuildingBlocksBy(input: ComplianceVesselBuildingBlocksByInput!): ComplianceVesselBuildingBlocksByConnection!\n",
    "\n",
    "            ''',\n",
    "\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"what are the ships surrounding india and what of them has imo=9987654\",\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(retrival.model_dump_json(indent=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "maritime",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
